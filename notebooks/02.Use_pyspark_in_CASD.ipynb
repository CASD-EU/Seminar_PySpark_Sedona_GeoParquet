{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Get started with spark\n",
    "\n",
    "In this tutorial, we will learn:\n",
    "- how to create a spark session\n",
    "- read a csv file\n",
    "- read a parquet file\n",
    "\n",
    "\n",
    "## 1. Create a spark session"
   ],
   "id": "b42cf971a64f18ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:31:02.995465Z",
     "start_time": "2025-08-06T13:31:02.832597Z"
    }
   },
   "cell_type": "code",
   "source": "from pyspark.sql import SparkSession, DataFrame",
   "id": "6fbe633fa74cd51c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:31:26.330211Z",
     "start_time": "2025-08-06T13:31:22.691019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a spark session in local mode\n",
    "spark = SparkSession.builder \\\n",
    "     .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .appName(\"Analyze_fr_immo_transactions\") \\\n",
    "    .getOrCreate()"
   ],
   "id": "dbcc286d4b68fd6d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:31:27.106719Z",
     "start_time": "2025-08-06T13:31:27.069719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# you can get and set configuration of your spark session any moments\n",
    "# get all conf\n",
    "spark.sparkContext.getConf().getAll()"
   ],
   "id": "45405f8a15ae8cea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.extraJavaOptions',\n",
       "  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n",
       " ('spark.driver.memory', '4g'),\n",
       " ('spark.driver.port', '55625'),\n",
       " ('spark.app.name', 'Analyze_fr_immo_transactions'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.host', 'LT-5CG4181HBL.casd.me'),\n",
       " ('spark.app.id', 'local-1754487085906'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.startTime', '1754487084817'),\n",
       " ('spark.app.submitTime', '1754487084627'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f32a5bef0a3d4ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> In this tutorial, we only focus on spark on local mode. CASD proposes `yarn` and `k8s` mode.",
   "id": "27aa649ec04cfd6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Read a csv file",
   "id": "6aa98d7f0a569594"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:31:38.345641Z",
     "start_time": "2025-08-06T13:31:33.364489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "csv_sample_file_path = \"C:/Users/PLIU/Documents/ubuntu_share/data_set/france_immobilier/transactions_sample.csv\"\n",
    "\n",
    "# the option header\n",
    "sample_df = spark.read.csv(csv_sample_file_path, header=True, inferSchema=True)"
   ],
   "id": "1a381ae6fd78177",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:31:42.602101Z",
     "start_time": "2025-08-06T13:31:42.249924Z"
    }
   },
   "cell_type": "code",
   "source": "sample_df.show(5)",
   "id": "7151e23236639a2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+--------+-----------+--------+--------------------+-----------+--------------------+-------------+-----+--------+-----------------+--------------------+----------------+----------------+-------------------+--------------------------+--------------------------+---------------------+-----------------------+\n",
      "|id_transaction|date_transaction|    prix|departement|id_ville|               ville|code_postal|             adresse|type_batiment| vefa|n_pieces|surface_habitable|id_parcelle_cadastre|        latitude|       longitude|surface_dependances|surface_locaux_industriels|surface_terrains_agricoles|surface_terrains_sols|surface_terrains_nature|\n",
      "+--------------+----------------+--------+-----------+--------+--------------------+-----------+--------------------+-------------+-----+--------+-----------------+--------------------+----------------+----------------+-------------------+--------------------------+--------------------------+---------------------+-----------------------+\n",
      "|      10160888|      2015-07-22|222500.0|         63|     247|               MUROL|      63790|         5148  COMBE|       Maison|false|       4|              123|      63247000ZO0165|45.5729726213494|2.94997597336221|                 {}|                        {}|                        {}|               {2387}|                     {}|\n",
      "|      10319766|      2024-06-18|218640.0|         73|      15|          LES ALLUES|      73550|45 RUE DU GRAND C...|  Appartement|false|       1|               23|      73015000AB0347|45.3987396582855|6.56760164004644|                {0}|                        {}|                        {}|                   {}|                     {}|\n",
      "|      11545562|      2020-07-23|254950.0|         77|     316|MORET-LOING-ET-OR...|      77250|1 RUE DE LA CROIX...|       Maison|false|       6|              124|      773161700B0305|48.3337616035885|2.78083033196279|                 {}|                        {}|                        {}|                {815}|                     {}|\n",
      "|      13891173|      2022-10-03|380000.0|         94|      81|     VITRY-SUR-SEINE|      94400|11 VOIE VICTOR MASSE|       Maison|false|       3|               93|      94081000AK0189| 48.796988276575|2.37555811653132|                 {}|                        {}|                        {}|                {208}|                     {}|\n",
      "|      11794772|      2018-07-12|258000.0|         77|     284|               MEAUX|      77100|14 RUE PIERRE BON...|       Maison|false|       5|               96|      77284000AW0090|48.9488159934431|2.89173438180231|                 {}|                        {}|                        {}|                   {}|                     {}|\n",
      "+--------------+----------------+--------+-----------+--------+--------------------+-----------+--------------------+-------------+-----+--------+-----------------+--------------------+----------------+----------------+-------------------+--------------------------+--------------------------+---------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:33:00.299208Z",
     "start_time": "2025-08-06T13:33:00.292776Z"
    }
   },
   "cell_type": "code",
   "source": "sample_df.printSchema()",
   "id": "b764b67fad6f529c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_transaction: integer (nullable = true)\n",
      " |-- date_transaction: date (nullable = true)\n",
      " |-- prix: double (nullable = true)\n",
      " |-- departement: integer (nullable = true)\n",
      " |-- id_ville: integer (nullable = true)\n",
      " |-- ville: string (nullable = true)\n",
      " |-- code_postal: integer (nullable = true)\n",
      " |-- adresse: string (nullable = true)\n",
      " |-- type_batiment: string (nullable = true)\n",
      " |-- vefa: boolean (nullable = true)\n",
      " |-- n_pieces: integer (nullable = true)\n",
      " |-- surface_habitable: integer (nullable = true)\n",
      " |-- id_parcelle_cadastre: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- surface_dependances: string (nullable = true)\n",
      " |-- surface_locaux_industriels: string (nullable = true)\n",
      " |-- surface_terrains_agricoles: string (nullable = true)\n",
      " |-- surface_terrains_sols: string (nullable = true)\n",
      " |-- surface_terrains_nature: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Read a parquet file\n",
    "\n"
   ],
   "id": "15e77e2aea3f0aad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:33:07.662096Z",
     "start_time": "2025-08-06T13:33:07.231341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fr_immo_transaction_path = \"C:/Users/PLIU/Documents/git/Seminar_PySpark_Sedona_GeoParquet/data/fr_immo_transaction.parquet\"\n",
    "fr_immo_transactions_df = spark.read.parquet(fr_immo_transaction_path)"
   ],
   "id": "446ea935a3539360",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:33:08.225438Z",
     "start_time": "2025-08-06T13:33:08.167123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "required_col = [\"id_transaction\",\"date_transaction\",\"prix\",\"departement\",\"ville\",\"code_postal\",\"adresse\",\"type_batiment\",\"n_pieces\",\"surface_habitable\",\"latitude\",\"longitude\"]\n",
    "clean_fr_immo_df = fr_immo_transactions_df.select(required_col)"
   ],
   "id": "6fb940ee1aa45c3d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:41:26.611783Z",
     "start_time": "2025-08-06T13:41:26.507557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cache the dataframe for better performence\n",
    "clean_fr_immo_df.cache()\n",
    "clean_fr_immo_df.show()"
   ],
   "id": "64bf43f61b938f74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+--------+-----------+--------------------+-----------+--------------------+-------------+--------+-----------------+----------------+----------------+\n",
      "|id_transaction|date_transaction|    prix|departement|               ville|code_postal|             adresse|type_batiment|n_pieces|surface_habitable|        latitude|       longitude|\n",
      "+--------------+----------------+--------+-----------+--------------------+-----------+--------------------+-------------+--------+-----------------+----------------+----------------+\n",
      "|        141653|      2014-01-02|197000.0|         01|             TREVOUX|       1600|  6346 MTE DES LILAS|  Appartement|       4|               84|45.9423014034837|4.77069364742062|\n",
      "|        141970|      2014-01-02|157500.0|         01|              VIRIAT|       1440|1369 RTE DE STRAS...|       Maison|       4|              103|46.2364072868351|5.26293493674271|\n",
      "|        139240|      2014-01-02|112000.0|         01|SAINT-JEAN-SUR-VEYLE|       1290|5174  SAINT JEAN ...|       Maison|       3|               78|46.2600767509964| 4.9186124567344|\n",
      "|        146016|      2014-01-02|173020.0|         01|             LAGNIEU|       1150|21 GR GRANDE RUE ...|       Maison|       4|               72|45.8990448750694|5.35421986570434|\n",
      "|        145911|      2014-01-03| 88000.0|         01|             OYONNAX|       1100| 29B RUE DE LA FORGE|  Appartement|       3|              104|46.2584083170745| 5.6408027525738|\n",
      "|        145024|      2014-01-03|202500.0|         01|ST ETIENNE-SUR-RE...|       1190|    5112  AU MOIROUX|       Maison|       6|              118|46.3900603987491|5.01770950682101|\n",
      "|        148141|      2014-01-03| 49023.3|         01|               BALAN|       1360|7 LOT AFU DE BARB...|       Maison|       5|              105|45.8321367961343|5.09791701908164|\n",
      "|        145399|      2014-01-03| 68000.0|         01|     BOURG-EN-BRESSE|       1000|10Z RUE EDGAR  QU...|  Appartement|       2|               44|  46.20385904116|5.22569295332627|\n",
      "|        143192|      2014-01-03|156750.0|         01|     BOURG-EN-BRESSE|       1000| 15 RUE DE MONTHOLON|  Appartement|       3|               83|46.2000838066075|5.21083723376748|\n",
      "|        146426|      2014-01-03|163640.0|         01|SAINT-MAURICE-DE-...|       1700|      40 AV DES ILES|  Appartement|       3|               84|45.8232892882996|4.97719901458052|\n",
      "|        141750|      2014-01-03|203000.0|         01|             DAGNEUX|       1120|733C RTE DE STE C...|       Maison|       5|               90|45.8599182503004|5.05532938199608|\n",
      "|        148109|      2014-01-03|126000.0|         01|             OYONNAX|       1100| 29B RUE DE LA FORGE|  Appartement|       4|              111|46.2584083170745| 5.6408027525738|\n",
      "|        146587|      2014-01-03|145000.0|         01|            FARAMANS|       1800|100 CHE DE LA COT...|       Maison|       4|               88|45.8984143194015| 5.1238429973443|\n",
      "|        142324|      2014-01-06|180230.0|         01|SAINT-GENIS-SUR-M...|       1380|   5013  LA TERRASSE|       Maison|       5|              200|46.3005918214866|5.01292534875678|\n",
      "|        147770|      2014-01-06|107000.0|         01|     BOURG-EN-BRESSE|       1000|18 RUE GEORGES GU...|  Appartement|       4|               81|46.1940166503064| 5.2085969704023|\n",
      "|        140120|      2014-01-06|177500.0|         01|BELLEGARDE-SUR-VA...|       1200|    23 RUE DE MUSSEL|       Maison|       6|              120|46.1012359876184|5.81606709511131|\n",
      "|        142088|      2014-01-06|165000.0|         01|BELLEGARDE-SUR-VA...|       1200|        10 RUE VIALA|  Appartement|       4|               87|46.1065010130505|5.82630764368207|\n",
      "|        146625|      2014-01-06|152000.0|         01|           BELLIGNAT|       1100|16 RUE GUSTAVE FL...|       Maison|       5|               92|46.2476079780747|5.63367658432816|\n",
      "|        146683|      2014-01-06|415000.0|         01|                 GEX|       1170|    111 RUE DE PARIS|  Appartement|       5|              117|46.3369095806716|6.05697509698794|\n",
      "|        144187|      2014-01-06|430500.0|         01|           MONTHIEUX|       1390|   300 GR GRANDE RUE|       Maison|       5|              175| 45.954218351011|4.94060008338832|\n",
      "+--------------+----------------+--------+-----------+--------------------+-----------+--------------------+-------------+--------+-----------------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T09:29:17.460930Z",
     "start_time": "2025-08-06T09:12:19.063884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# this steps requires many memory to run, and take 20mins to finish. So be careful.\n",
    "report = ProfileReport(clean_fr_immo_df)\n",
    "report.to_file(\"fr_immo_transactions_report.html\")"
   ],
   "id": "ee23a27368014460",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PLIU\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:  85%|████████▌ | 17/20 [16:37<02:56, 58.69s/it, Detecting duplicates]                \n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] No connection could be made because the target machine actively refused it",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPy4JJavaError\u001B[39m                             Traceback (most recent call last)",
      "    \u001B[31m[... skipping hidden 1 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      3\u001B[39m report = ProfileReport(clean_fr_immo_df)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[43mreport\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_file\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfr_immo_transactions_report.html\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\ydata_profiling\\profile_report.py:381\u001B[39m, in \u001B[36mProfileReport.to_file\u001B[39m\u001B[34m(self, output_file, silent)\u001B[39m\n\u001B[32m    379\u001B[39m     create_html_assets(\u001B[38;5;28mself\u001B[39m.config, output_file)\n\u001B[32m--> \u001B[39m\u001B[32m381\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mto_html\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_file.suffix != \u001B[33m\"\u001B[39m\u001B[33m.html\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\ydata_profiling\\profile_report.py:498\u001B[39m, in \u001B[36mProfileReport.to_html\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    491\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Generate and return complete template as lengthy string\u001B[39;00m\n\u001B[32m    492\u001B[39m \u001B[33;03m    for using with frameworks.\u001B[39;00m\n\u001B[32m    493\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    496\u001B[39m \n\u001B[32m    497\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m498\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mhtml\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\ydata_profiling\\profile_report.py:294\u001B[39m, in \u001B[36mProfileReport.html\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    293\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._html \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m294\u001B[39m     \u001B[38;5;28mself\u001B[39m._html = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_render_html\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    295\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._html\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\ydata_profiling\\profile_report.py:411\u001B[39m, in \u001B[36mProfileReport._render_html\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    409\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mydata_profiling\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mreport\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpresentation\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mflavours\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m HTMLReport\n\u001B[32m--> \u001B[39m\u001B[32m411\u001B[39m report = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mreport\u001B[49m\n\u001B[32m    413\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(\n\u001B[32m    414\u001B[39m     total=\u001B[32m1\u001B[39m, desc=\u001B[33m\"\u001B[39m\u001B[33mRender HTML\u001B[39m\u001B[33m\"\u001B[39m, disable=\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.progress_bar\n\u001B[32m    415\u001B[39m ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\ydata_profiling\\profile_report.py:288\u001B[39m, in \u001B[36mProfileReport.report\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    287\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._report \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m288\u001B[39m     \u001B[38;5;28mself\u001B[39m._report = get_report_structure(\u001B[38;5;28mself\u001B[39m.config, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdescription_set\u001B[49m)\n\u001B[32m    289\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._report\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\ydata_profiling\\profile_report.py:270\u001B[39m, in \u001B[36mProfileReport.description_set\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    269\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._description_set \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m270\u001B[39m     \u001B[38;5;28mself\u001B[39m._description_set = \u001B[43mdescribe_df\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    271\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    272\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    273\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msummarizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    274\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtypeset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    275\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    276\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    277\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._description_set\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\ydata_profiling\\model\\describe.py:169\u001B[39m, in \u001B[36mdescribe\u001B[39m\u001B[34m(config, df, summarizer, typeset, sample)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;66;03m# Duplicates\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m169\u001B[39m metrics, duplicates = \u001B[43mprogress\u001B[49m\u001B[43m(\u001B[49m\u001B[43mget_duplicates\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpbar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mDetecting duplicates\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    170\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msupported_columns\u001B[49m\n\u001B[32m    171\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    172\u001B[39m table_stats.update(metrics)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\ydata_profiling\\utils\\progress_bar.py:11\u001B[39m, in \u001B[36mprogress.<locals>.inner\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     10\u001B[39m bar.set_postfix_str(message)\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m ret = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m bar.update()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\multimethod\\__init__.py:375\u001B[39m, in \u001B[36mmultimethod.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    374\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m375\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    376\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m ex:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\ydata_profiling\\model\\spark\\duplicates_spark.py:49\u001B[39m, in \u001B[36mget_duplicates_spark\u001B[39m\u001B[34m(config, df, supported_columns)\u001B[39m\n\u001B[32m     42\u001B[39m duplicated_df = (\n\u001B[32m     43\u001B[39m     df.groupBy(df.columns)\n\u001B[32m     44\u001B[39m     .agg(F.count(\u001B[33m\"\u001B[39m\u001B[33m*\u001B[39m\u001B[33m\"\u001B[39m).alias(duplicates_key))\n\u001B[32m     45\u001B[39m     .withColumn(duplicates_key, F.col(duplicates_key).cast(\u001B[33m\"\u001B[39m\u001B[33mint\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m     46\u001B[39m     .filter(F.col(duplicates_key) > \u001B[32m1\u001B[39m)\n\u001B[32m     47\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m49\u001B[39m metrics[\u001B[33m\"\u001B[39m\u001B[33mn_duplicates\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mduplicated_df\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcount\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     50\u001B[39m metrics[\u001B[33m\"\u001B[39m\u001B[33mp_duplicates\u001B[39m\u001B[33m\"\u001B[39m] = metrics[\u001B[33m\"\u001B[39m\u001B[33mn_duplicates\u001B[39m\u001B[33m\"\u001B[39m] / df.count()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:1240\u001B[39m, in \u001B[36mDataFrame.count\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1218\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001B[39;00m\n\u001B[32m   1219\u001B[39m \n\u001B[32m   1220\u001B[39m \u001B[33;03m.. versionadded:: 1.3.0\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1238\u001B[39m \u001B[33;03m3\u001B[39;00m\n\u001B[32m   1239\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1240\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_jdf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcount\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001B[39m, in \u001B[36mJavaMember.__call__\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m   1321\u001B[39m answer = \u001B[38;5;28mself\u001B[39m.gateway_client.send_command(command)\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m return_value = \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1323\u001B[39m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1325\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001B[39m, in \u001B[36mcapture_sql_exception.<locals>.deco\u001B[39m\u001B[34m(*a, **kw)\u001B[39m\n\u001B[32m    178\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m179\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\protocol.py:326\u001B[39m, in \u001B[36mget_return_value\u001B[39m\u001B[34m(answer, gateway_client, target_id, name)\u001B[39m\n\u001B[32m    325\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[32m1\u001B[39m] == REFERENCE_TYPE:\n\u001B[32m--> \u001B[39m\u001B[32m326\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[32m    327\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.\n\u001B[32m    328\u001B[39m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m, name), value)\n\u001B[32m    329\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31m<class 'str'>\u001B[39m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mConnectionRefusedError\u001B[39m                    Traceback (most recent call last)",
      "    \u001B[31m[... skipping hidden 1 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2205\u001B[39m, in \u001B[36mInteractiveShell.showtraceback\u001B[39m\u001B[34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[39m\n\u001B[32m   2202\u001B[39m         traceback.print_exc()\n\u001B[32m   2203\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2205\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_showtraceback\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2206\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.call_pdb:\n\u001B[32m   2207\u001B[39m     \u001B[38;5;66;03m# drop into debugger\u001B[39;00m\n\u001B[32m   2208\u001B[39m     \u001B[38;5;28mself\u001B[39m.debugger(force=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\ipykernel\\zmqshell.py:587\u001B[39m, in \u001B[36mZMQInteractiveShell._showtraceback\u001B[39m\u001B[34m(self, etype, evalue, stb)\u001B[39m\n\u001B[32m    581\u001B[39m sys.stdout.flush()\n\u001B[32m    582\u001B[39m sys.stderr.flush()\n\u001B[32m    584\u001B[39m exc_content = {\n\u001B[32m    585\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtraceback\u001B[39m\u001B[33m\"\u001B[39m: stb,\n\u001B[32m    586\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mename\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mstr\u001B[39m(etype.\u001B[34m__name__\u001B[39m),\n\u001B[32m--> \u001B[39m\u001B[32m587\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mevalue\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    588\u001B[39m }\n\u001B[32m    590\u001B[39m dh = \u001B[38;5;28mself\u001B[39m.displayhook\n\u001B[32m    591\u001B[39m \u001B[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001B[39;00m\n\u001B[32m    592\u001B[39m \u001B[38;5;66;03m# to pick up\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\protocol.py:471\u001B[39m, in \u001B[36mPy4JJavaError.__str__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    469\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__str__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    470\u001B[39m     gateway_client = \u001B[38;5;28mself\u001B[39m.java_exception._gateway_client\n\u001B[32m--> \u001B[39m\u001B[32m471\u001B[39m     answer = \u001B[43mgateway_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mexception_cmd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    472\u001B[39m     return_value = get_return_value(answer, gateway_client, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    473\u001B[39m     \u001B[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001B[39;00m\n\u001B[32m    474\u001B[39m     \u001B[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001B[39;00m\n\u001B[32m    475\u001B[39m     \u001B[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\java_gateway.py:1036\u001B[39m, in \u001B[36mGatewayClient.send_command\u001B[39m\u001B[34m(self, command, retry, binary)\u001B[39m\n\u001B[32m   1015\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msend_command\u001B[39m(\u001B[38;5;28mself\u001B[39m, command, retry=\u001B[38;5;28;01mTrue\u001B[39;00m, binary=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m   1016\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001B[39;00m\n\u001B[32m   1017\u001B[39m \u001B[33;03m       called directly by Py4J users. It is usually called by\u001B[39;00m\n\u001B[32m   1018\u001B[39m \u001B[33;03m       :class:`JavaMember` instances.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1034\u001B[39m \u001B[33;03m     if `binary` is `True`.\u001B[39;00m\n\u001B[32m   1035\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1036\u001B[39m     connection = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1037\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1038\u001B[39m         response = connection.send_command(command)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\clientserver.py:284\u001B[39m, in \u001B[36mJavaClient._get_connection\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    281\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    283\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m connection \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m connection.socket \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m284\u001B[39m     connection = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_create_new_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    285\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m connection\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\clientserver.py:291\u001B[39m, in \u001B[36mJavaClient._create_new_connection\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    287\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_create_new_connection\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    288\u001B[39m     connection = ClientServerConnection(\n\u001B[32m    289\u001B[39m         \u001B[38;5;28mself\u001B[39m.java_parameters, \u001B[38;5;28mself\u001B[39m.python_parameters,\n\u001B[32m    290\u001B[39m         \u001B[38;5;28mself\u001B[39m.gateway_property, \u001B[38;5;28mself\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m291\u001B[39m     \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconnect_to_java_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    292\u001B[39m     \u001B[38;5;28mself\u001B[39m.set_thread_connection(connection)\n\u001B[32m    293\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m connection\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\clientserver.py:438\u001B[39m, in \u001B[36mClientServerConnection.connect_to_java_server\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    435\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ssl_context:\n\u001B[32m    436\u001B[39m     \u001B[38;5;28mself\u001B[39m.socket = \u001B[38;5;28mself\u001B[39m.ssl_context.wrap_socket(\n\u001B[32m    437\u001B[39m         \u001B[38;5;28mself\u001B[39m.socket, server_hostname=\u001B[38;5;28mself\u001B[39m.java_address)\n\u001B[32m--> \u001B[39m\u001B[32m438\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msocket\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mjava_address\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mjava_port\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    439\u001B[39m \u001B[38;5;28mself\u001B[39m.stream = \u001B[38;5;28mself\u001B[39m.socket.makefile(\u001B[33m\"\u001B[39m\u001B[33mrb\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    440\u001B[39m \u001B[38;5;28mself\u001B[39m.is_connected = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[31mConnectionRefusedError\u001B[39m: [WinError 10061] No connection could be made because the target machine actively refused it"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] No connection could be made because the target machine actively refused it",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mConnectionRefusedError\u001B[39m                    Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py:128\u001B[39m, in \u001B[36m_pseudo_sync_runner\u001B[39m\u001B[34m(coro)\u001B[39m\n\u001B[32m    120\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    121\u001B[39m \u001B[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001B[39;00m\n\u001B[32m    122\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    125\u001B[39m \u001B[33;03mCredit to Nathaniel Smith\u001B[39;00m\n\u001B[32m    126\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    127\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m     coro.send(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    130\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m exc.value\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3413\u001B[39m, in \u001B[36mInteractiveShell.run_cell_async\u001B[39m\u001B[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001B[39m\n\u001B[32m   3409\u001B[39m exec_count = \u001B[38;5;28mself\u001B[39m.execution_count\n\u001B[32m   3410\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m result.error_in_exec:\n\u001B[32m   3411\u001B[39m     \u001B[38;5;66;03m# Store formatted traceback and error details\u001B[39;00m\n\u001B[32m   3412\u001B[39m     \u001B[38;5;28mself\u001B[39m.history_manager.exceptions[exec_count] = (\n\u001B[32m-> \u001B[39m\u001B[32m3413\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_format_exception_for_storage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m.\u001B[49m\u001B[43merror_in_exec\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3414\u001B[39m     )\n\u001B[32m   3416\u001B[39m \u001B[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001B[39;00m\n\u001B[32m   3417\u001B[39m \u001B[38;5;28mself\u001B[39m.execution_count += \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3474\u001B[39m, in \u001B[36mInteractiveShell._format_exception_for_storage\u001B[39m\u001B[34m(self, exception, filename, running_compiled_code)\u001B[39m\n\u001B[32m   3470\u001B[39m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   3471\u001B[39m             \u001B[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001B[39;00m\n\u001B[32m   3472\u001B[39m             stb = traceback.format_exception(etype, evalue, tb)\n\u001B[32m-> \u001B[39m\u001B[32m3474\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[33m\"\u001B[39m\u001B[33mename\u001B[39m\u001B[33m\"\u001B[39m: etype.\u001B[34m__name__\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mevalue\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m)\u001B[49m, \u001B[33m\"\u001B[39m\u001B[33mtraceback\u001B[39m\u001B[33m\"\u001B[39m: stb}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\protocol.py:471\u001B[39m, in \u001B[36mPy4JJavaError.__str__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    469\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__str__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    470\u001B[39m     gateway_client = \u001B[38;5;28mself\u001B[39m.java_exception._gateway_client\n\u001B[32m--> \u001B[39m\u001B[32m471\u001B[39m     answer = \u001B[43mgateway_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mexception_cmd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    472\u001B[39m     return_value = get_return_value(answer, gateway_client, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    473\u001B[39m     \u001B[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001B[39;00m\n\u001B[32m    474\u001B[39m     \u001B[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001B[39;00m\n\u001B[32m    475\u001B[39m     \u001B[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\java_gateway.py:1036\u001B[39m, in \u001B[36mGatewayClient.send_command\u001B[39m\u001B[34m(self, command, retry, binary)\u001B[39m\n\u001B[32m   1015\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msend_command\u001B[39m(\u001B[38;5;28mself\u001B[39m, command, retry=\u001B[38;5;28;01mTrue\u001B[39;00m, binary=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m   1016\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001B[39;00m\n\u001B[32m   1017\u001B[39m \u001B[33;03m       called directly by Py4J users. It is usually called by\u001B[39;00m\n\u001B[32m   1018\u001B[39m \u001B[33;03m       :class:`JavaMember` instances.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1034\u001B[39m \u001B[33;03m     if `binary` is `True`.\u001B[39;00m\n\u001B[32m   1035\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1036\u001B[39m     connection = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1037\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1038\u001B[39m         response = connection.send_command(command)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\clientserver.py:284\u001B[39m, in \u001B[36mJavaClient._get_connection\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    281\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    283\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m connection \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m connection.socket \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m284\u001B[39m     connection = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_create_new_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    285\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m connection\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\clientserver.py:291\u001B[39m, in \u001B[36mJavaClient._create_new_connection\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    287\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_create_new_connection\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    288\u001B[39m     connection = ClientServerConnection(\n\u001B[32m    289\u001B[39m         \u001B[38;5;28mself\u001B[39m.java_parameters, \u001B[38;5;28mself\u001B[39m.python_parameters,\n\u001B[32m    290\u001B[39m         \u001B[38;5;28mself\u001B[39m.gateway_property, \u001B[38;5;28mself\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m291\u001B[39m     \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconnect_to_java_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    292\u001B[39m     \u001B[38;5;28mself\u001B[39m.set_thread_connection(connection)\n\u001B[32m    293\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m connection\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\git\\Seminar_PySpark_Sedona_GeoParquet\\sedona_venv\\Lib\\site-packages\\py4j\\clientserver.py:438\u001B[39m, in \u001B[36mClientServerConnection.connect_to_java_server\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    435\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ssl_context:\n\u001B[32m    436\u001B[39m     \u001B[38;5;28mself\u001B[39m.socket = \u001B[38;5;28mself\u001B[39m.ssl_context.wrap_socket(\n\u001B[32m    437\u001B[39m         \u001B[38;5;28mself\u001B[39m.socket, server_hostname=\u001B[38;5;28mself\u001B[39m.java_address)\n\u001B[32m--> \u001B[39m\u001B[32m438\u001B[39m \u001B[38;5;28mself\u001B[39m.socket.connect((\u001B[38;5;28mself\u001B[39m.java_address, \u001B[38;5;28mself\u001B[39m.java_port))\n\u001B[32m    439\u001B[39m \u001B[38;5;28mself\u001B[39m.stream = \u001B[38;5;28mself\u001B[39m.socket.makefile(\u001B[33m\"\u001B[39m\u001B[33mrb\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    440\u001B[39m \u001B[38;5;28mself\u001B[39m.is_connected = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[31mConnectionRefusedError\u001B[39m: [WinError 10061] No connection could be made because the target machine actively refused it"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Clean dataframe\n",
    "\n",
    "We want to check some basic information of the dataframe:\n",
    "- Total row count\n",
    "- schema(e.g.column name and data type)\n",
    "- Empty rows (all-null)\n",
    "- Rows with any missing values\n",
    "- Duplicate rows\n",
    "- Rows containing empty strings\n",
    "- Nulls count per column"
   ],
   "id": "b998c95a2e3087e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:31:49.406227Z",
     "start_time": "2025-08-06T13:31:49.381229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import sum as spark_sum\n",
    "from pyspark.sql.functions import col, when, isnan, trim\n",
    "import pyspark.sql.types as spark_types\n",
    "\n",
    "def get_empty_row_count_per_column(df:DataFrame):\n",
    "    totalRowCount = df.count()\n",
    "\n",
    "    nullSymbols = [\"?\",\"-\"]\n",
    "    aggExpression = []\n",
    "\n",
    "    # step2: build the condition expression for detecting various null case\n",
    "    for colName in df.columns:\n",
    "        # temporal col name\n",
    "        nullCountCol = f\"{colName}__null\"\n",
    "        nanCountCol = f\"{colName}__nan\"\n",
    "        blankCountCol = f\"{colName}__blank\"\n",
    "        nullSymbolCountCol = f\"{colName}__symbol\"\n",
    "        c = col(colName)\n",
    "        colType = df.schema[colName].dataType\n",
    "        # always test null\n",
    "        nullExpr = when(c.isNull(), 1).otherwise(0).alias(nullCountCol)\n",
    "        aggExpression.append(nullExpr)\n",
    "        # test isnan for only numeric columns\n",
    "        nanExpr = when(isnan(c), 1).otherwise(0).alias(nanCountCol)\n",
    "        if isinstance(colType, spark_types.NumericType):\n",
    "            aggExpression.append(nanExpr)\n",
    "        # string null value only for string columns\n",
    "        if isinstance(colType, spark_types.StringType):\n",
    "            aggExpression.append(when(trim(c) == \"\", 1).otherwise(0).alias(blankCountCol))\n",
    "            aggExpression.append(when(c.isin(nullSymbols), 1).otherwise(0).alias(nullSymbolCountCol))\n",
    "\n",
    "        # Perform full-column conditional tagging\n",
    "    flaggedDf = df.select(*aggExpression)\n",
    "\n",
    "    # step3: sum all per-column null case flags in one single pass\n",
    "    try:\n",
    "        summed = flaggedDf.agg(*[spark_sum(c).alias(c) for c in flaggedDf.columns]).collect()[0].asDict()\n",
    "    except Exception as e:\n",
    "        print(f\"Aggregation failed on flaggedDf columns: {flaggedDf.columns}: {e}\")\n",
    "\n",
    "    result = []\n",
    "    # step4: build a list of dict which contains all info for the final result dataframe\n",
    "    for colName in df.columns:\n",
    "        # temporal col name\n",
    "        nullCountCol = f\"{colName}__null\"\n",
    "        nanCountCol = f\"{colName}__nan\"\n",
    "        blankCountCol = f\"{colName}__blank\"\n",
    "        nullSymbolCountCol = f\"{colName}__symbol\"\n",
    "        nullCount = summed.get(nullCountCol, 0)\n",
    "        nanCount = summed.get(nanCountCol, 0)\n",
    "        blankCount = summed.get(blankCountCol, 0)\n",
    "        symbolCount = summed.get(nullSymbolCountCol, 0)\n",
    "        totalEmpty = nullCount + nanCount + blankCount + symbolCount\n",
    "\n",
    "        result.append((\n",
    "            colName, nullCount, nanCount, blankCount,\n",
    "            symbolCount, totalEmpty, totalRowCount\n",
    "        ))\n",
    "    # convert the list of dict into a new dataframe\n",
    "    resDf = spark.createDataFrame(result, [\"column_name\", \"null_count\", \"nan_count\", \"blank_count\",\n",
    "                                                \"null_symbol_count\", \"total_empty_row_count\",\n",
    "                                                \"total_row_count\"])\n",
    "    #\n",
    "\n",
    "    return resDf\n"
   ],
   "id": "649df8a50966851b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:42:16.048356Z",
     "start_time": "2025-08-06T13:42:16.042357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_duplicated_row_count(df:DataFrame):\n",
    "     duplicate_row_count = df.count() - df.dropDuplicates().count()\n",
    "     print(f\"Duplicate row count: {duplicate_row_count}\")\n"
   ],
   "id": "15c5dfa28326a370",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:33:46.093926Z",
     "start_time": "2025-08-06T13:33:37.642930Z"
    }
   },
   "cell_type": "code",
   "source": "null_col_stats = get_empty_row_count_per_column(clean_fr_immo_df)",
   "id": "63785b8725cd4cba",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:34:35.993411Z",
     "start_time": "2025-08-06T13:34:29.804556Z"
    }
   },
   "cell_type": "code",
   "source": "null_col_stats.show(20)",
   "id": "73face0dd0d004b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+---------+-----------+-----------------+---------------------+---------------+\n",
      "|      column_name|null_count|nan_count|blank_count|null_symbol_count|total_empty_row_count|total_row_count|\n",
      "+-----------------+----------+---------+-----------+-----------------+---------------------+---------------+\n",
      "|   id_transaction|         0|        0|          0|                0|                    0|        9141573|\n",
      "| date_transaction|         0|        0|          0|                0|                    0|        9141573|\n",
      "|             prix|         0|        0|          0|                0|                    0|        9141573|\n",
      "|      departement|         0|        0|          0|                0|                    0|        9141573|\n",
      "|            ville|         0|        0|          0|                0|                    0|        9141573|\n",
      "|      code_postal|         0|        0|          0|                0|                    0|        9141573|\n",
      "|          adresse|         0|        0|          1|                0|                    1|        9141573|\n",
      "|    type_batiment|         0|        0|          0|                0|                    0|        9141573|\n",
      "|         n_pieces|         0|        0|          0|                0|                    0|        9141573|\n",
      "|surface_habitable|         0|        0|          0|                0|                    0|        9141573|\n",
      "|         latitude|         0|        0|          0|                0|                    0|        9141573|\n",
      "|        longitude|         0|        0|          0|                0|                    0|        9141573|\n",
      "+-----------------+----------+---------+-----------+-----------------+---------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T13:42:44.549456Z",
     "start_time": "2025-08-06T13:42:26.397538Z"
    }
   },
   "cell_type": "code",
   "source": "get_duplicated_row_count(clean_fr_immo_df)",
   "id": "a4c6a7e9dc882ad2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate row count: 0\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2bdea439e9e09099"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# creating a geometry column\n",
    "\n"
   ],
   "id": "25189f710b996015"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3d30347ec5b67f46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1d427b8181b3b735"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
