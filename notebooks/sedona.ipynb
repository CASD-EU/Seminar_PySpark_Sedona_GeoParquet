{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Spatial data processing with apache sedona\n",
    "\n",
    "[Apache Sedona](https://sedona.apache.org/latest/) is a cluster computing system for processing `large-scale spatial data`. In this tutorial, we will learn\n",
    "how to use sedona in a `pyspark environment`. It supports other `cluster computing systems`, such as `Apache Flink, and Snowflake`. But we will not cover them in this tutorial.\n",
    "\n",
    "## 0. Pyspark and sedona internals\n",
    "\n",
    "`PySpark` is a Python API for Apache Spark.\n",
    " distributed computations in JVM-based executors.\n",
    "\n",
    "2. Sedona Core (Scala)\n",
    "Sedona adds support for spatial data types and operations to Spark.\n",
    "\n",
    "It includes:\n",
    "\n",
    "Spatial RDDs\n",
    "\n",
    "Geometry types (Point, Polygon, etc.)\n",
    "\n",
    "Spatial indexes (QuadTree, RTree)\n",
    "\n",
    "Spatial operations (joins, predicates)\n",
    "\n",
    "3. Py4J Bridge\n",
    "PySpark uses Py4J to connect the Python driver to the JVM.\n",
    "\n",
    "Sedona functions you call in Python (e.g., ST_Point, ST_Within) are just Python wrappers that translate calls to JVM methods.\n",
    "Sedona offers a python package `apache-sedona[]`\n",
    "## 1. Prepare sedona in your dev environment\n",
    "\n",
    "### 1.1 check the required jar files\n",
    "\n",
    "As I explained before, sedona is written in `scala`, and released as `.jar` files.\n",
    "\n",
    "2. Install the python dependencies\n",
    "pip install apache-sedona[spark]\n"
   ],
   "id": "e06a7c7f012c18dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Prepare sedona in your dev environment\n",
    "\n",
    "### 1.1 check the required jar files\n",
    "\n",
    "As I explained before, sedona is written in `scala`, and released as `.jar` files.\n",
    "\n",
    "2. Install the python dependencies\n",
    "pip install apache-sedona[spark]"
   ],
   "id": "be2d1740564a6e59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import trim, split, expr, col"
   ],
   "id": "908c2c0a95382624"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# build a sedona session offline\n",
    "project_root_dir = Path.cwd().parent.parent"
   ],
   "id": "13dbac65c9081d9f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
